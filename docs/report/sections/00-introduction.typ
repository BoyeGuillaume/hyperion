= Introduction

Hyperion is a framework designed to enable scalable, *high-performance applications* in a *platform-agnostic way*. Its goal is to let developers write an algorithm once and then obtain efficient execution across a wide range of targets, including single-core `CPU`s, multicore `CPU`s, multi-node clusters, `GPU`s, `TPU`s, and `FPGA`s.

Today, achieving high performance typically requires rewriting the same program several times. A common workflow starts with a simple draft used for testing, followed by a multithreaded version for multicore CPUs. If performance is still insufficient, the program may be rewritten again for distributed execution across multiple CPU nodes, and later rewritten yet again to target accelerators such as GPUs. In embedded contexts, further rewrites are often needed to fit the constraints and programming model of FPGAs or specialized hardware. This process is time consuming, difficult to maintain, and error prone, and it makes it hard to keep a single codebase working reliably across all contexts. Addressing this problem is the core objective of Hyperion.

Hyperion aims to achieve this through four main components. First, it relies on a generic intermediate representation, inspired by LLVM IR, to express programs in a way that is independent of any single architecture. Second, it introduces optimization methods that go beyond traditional compiler passes by using formal verification and automatic theorem derivation to discover sound program transformations. These transformations can enable non-obvious changes, including changes that reduce the asymptotic complexity of an algorithm without changing its behavior. Third, Hyperion uses the derived theorems to automate parallelization, generating parallel implementations when correctness can be justified by the underlying proofs. Fourth, Hyperion targets heterogeneous execution, with the goal of running and scaling programs across mixed clusters of devices. In particular, it aims to make cross-vendor accelerator scaling practical, such as running across both NVIDIA and AMD GPUs, which is still difficult or unsupported in many existing frameworks.

To support different deployment scenarios, Hyperion is planned to operate in two complementary modes. In an ahead-of-time compilation mode, it should be able to generate compiled binaries and standalone programs suitable for deployment, including on embedded systems. In a just-in-time mode, it is intended to compile and optimize at runtime, enabling a tradeoff between compilation cost and execution speed. This would allow kernels to be specialized based on observed usage and input characteristics, and would enable dynamic scheduling decisions when previously unseen bottlenecks arise during execution.

